{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+---+---+---+----+----+----+----+----+---+----+----+---+-------------------------------------------------------+-----+\n",
      "|mac         |id   |f1 |f2 |f3 |f4  |f5  |f6  |f7  |f8  |f9 |f10 |f11 |f12|features                                               |label|\n",
      "+------------+-----+---+---+---+----+----+----+----+----+---+----+----+---+-------------------------------------------------------+-----+\n",
      "|0008221E6CF5|39226|0.0|0.0|0.0|8.0 |2.0 |2.0 |1.0 |14.0|6.0|12.0|15.0|5.0|[0.0,0.0,0.0,8.0,2.0,2.0,1.0,14.0,6.0,12.0,15.0,5.0]   |1.0  |\n",
      "|000EC6DC7BE2|49814|0.0|0.0|0.0|14.0|12.0|6.0 |13.0|12.0|7.0|11.0|14.0|2.0|[0.0,0.0,0.0,14.0,12.0,6.0,13.0,12.0,7.0,11.0,14.0,2.0]|2.0  |\n",
      "|001636154AF9|49813|0.0|0.0|1.0|6.0 |3.0 |6.0 |1.0 |5.0 |4.0|10.0|15.0|9.0|[0.0,0.0,1.0,6.0,3.0,6.0,1.0,5.0,4.0,10.0,15.0,9.0]    |5.0  |\n",
      "|0016785B0DF5|49810|0.0|0.0|1.0|6.0 |7.0 |8.0 |5.0 |11.0|0.0|13.0|15.0|5.0|[0.0,0.0,1.0,6.0,7.0,8.0,5.0,11.0,0.0,13.0,15.0,5.0]   |3.0  |\n",
      "|0019CBF145D0|49807|0.0|0.0|1.0|9.0 |12.0|11.0|15.0|1.0 |4.0|5.0 |13.0|0.0|[0.0,0.0,1.0,9.0,12.0,11.0,15.0,1.0,4.0,5.0,13.0,0.0]  |0.0  |\n",
      "+------------+-----+---+---+---+----+----+----+----+----+---+----+----+---+-------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "trainDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF')\n",
    "\n",
    "trainDF = trainDF.withColumn('m1',substring(trainDF.mac,1,1)).\\\n",
    "      withColumn('m2',substring(trainDF.mac,2,1)).\\\n",
    "      withColumn('m3',substring(trainDF.mac,3,1)).\\\n",
    "      withColumn('m4',substring(trainDF.mac,4,1)).\\\n",
    "      withColumn('m5',substring(trainDF.mac,5,1)).\\\n",
    "      withColumn('m6',substring(trainDF.mac,6,1)).\\\n",
    "      withColumn('m7',substring(trainDF.mac,7,1)).\\\n",
    "      withColumn('m8',substring(trainDF.mac,8,1)).\\\n",
    "      withColumn('m9',substring(trainDF.mac,9,1)).\\\n",
    "      withColumn('m10',substring(trainDF.mac,10,1)).\\\n",
    "      withColumn('m11',substring(trainDF.mac,11,1)).\\\n",
    "      withColumn('m12',substring(trainDF.mac,12,1))\n",
    "\n",
    "df = trainDF.withColumn('f1',conv(trainDF.m1, 16, 10)).withColumn('f2',conv(trainDF.m2, 16, 10)).\\\n",
    "        withColumn('f3',conv(trainDF.m3, 16, 10)).withColumn('f4',conv(trainDF.m4, 16, 10)).\\\n",
    "        withColumn('f5',conv(trainDF.m5, 16, 10)).withColumn('f6',conv(trainDF.m6, 16, 10)).\\\n",
    "        withColumn('f7',conv(trainDF.m7, 16, 10)).withColumn('f8',conv(trainDF.m8, 16, 10)).\\\n",
    "        withColumn('f9',conv(trainDF.m9, 16, 10)).withColumn('f10',conv(trainDF.m10, 16, 10)).\\\n",
    "        withColumn('f11',conv(trainDF.m11, 16, 10)).withColumn('f12',conv(trainDF.m12, 16, 10))\n",
    "\n",
    "df = df.select('mac','id',col('f1').cast('float'),col('f2').cast('float')\\\n",
    "               ,col('f3').cast('float'),col('f4').cast('float')\\\n",
    "               ,col('f5').cast('float'),col('f6').cast('float')\\\n",
    "               ,col('f7').cast('float'),col('f8').cast('float')\\\n",
    "               ,col('f9').cast('float'),col('f10').cast('float')\\\n",
    "               ,col('f11').cast('float'),col('f12').cast('float'))\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vec = VectorAssembler(inputCols=['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12'],outputCol='features')\n",
    "new_df = vec.transform(df)\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "si = StringIndexer(inputCol='id', outputCol='label')\n",
    "si_model = si.fit(new_df)\n",
    "df_final = si_model.transform(new_df)\n",
    "\n",
    "df_final.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.write.mode('overwrite').parquet('hdfs:///data/user/hive/warehouse/ian/feature/testDF_mac_12',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with non cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/trainDF_mac_12')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF_mac_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7360274, 3152812)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count(),testDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol='label',featuresCol='features',numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mac', 'string'),\n",
       " ('id', 'string'),\n",
       " ('f1', 'float'),\n",
       " ('f2', 'float'),\n",
       " ('f3', 'float'),\n",
       " ('f4', 'float'),\n",
       " ('f5', 'float'),\n",
       " ('f6', 'float'),\n",
       " ('f7', 'float'),\n",
       " ('f8', 'float'),\n",
       " ('f9', 'float'),\n",
       " ('f10', 'float'),\n",
       " ('f11', 'float'),\n",
       " ('f12', 'float'),\n",
       " ('features', 'vector'),\n",
       " ('label', 'double'),\n",
       " ('rawPrediction', 'vector'),\n",
       " ('probability', 'vector'),\n",
       " ('prediction', 'double')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------+\n",
      "|label|prediction|mac         |\n",
      "+-----+----------+------------+\n",
      "|1.0  |2.0       |0008221E6CF5|\n",
      "|2.0  |2.0       |000EC6DC7BE2|\n",
      "|5.0  |4.0       |001636154AF9|\n",
      "|3.0  |0.0       |0016785B0DF5|\n",
      "|0.0  |1.0       |0019CBF145D0|\n",
      "+-----+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('label','prediction','mac').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46540548564265805"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with CV & hp tuning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/trainDF_mac_12')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF_mac_12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "import numpy as np\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "paramGrid_rf = ParamGridBuilder()\\\n",
    "       .addGrid(rf.maxDepth,[3,4,5,6,7,8,9,10])\\\n",
    "       .addGrid(rf.numTrees,[10,15,20,25,30])\\\n",
    "       .build()\n",
    "\n",
    "crossval_rf = CrossValidator(estimator=rf,\n",
    "                            estimatorParamMaps=paramGrid_rf,\n",
    "                            evaluator=MulticlassClassificationEvaluator(),\n",
    "                            numFolds=5)\n",
    "\n",
    "cvModel_rf = crossval_rf.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8072330351444996"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_rf = cvModel_rf.bestModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_eval_rf = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_eval_rf.evaluate(best_model_rf.transform(testDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model_rf.save('hdfs:///data/user/hive/warehouse/ian/model/mac_id_12_rf_cv_tuning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = best_model_rf.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mac', 'string'),\n",
       " ('id', 'string'),\n",
       " ('f1', 'float'),\n",
       " ('f2', 'float'),\n",
       " ('f3', 'float'),\n",
       " ('f4', 'float'),\n",
       " ('f5', 'float'),\n",
       " ('f6', 'float'),\n",
       " ('f7', 'float'),\n",
       " ('f8', 'float'),\n",
       " ('f9', 'float'),\n",
       " ('f10', 'float'),\n",
       " ('f11', 'float'),\n",
       " ('f12', 'float'),\n",
       " ('features', 'vector'),\n",
       " ('label', 'double'),\n",
       " ('rawPrediction', 'vector'),\n",
       " ('probability', 'vector'),\n",
       " ('prediction', 'double')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|mac         |id   |label|probability                                                                                                                                                                                                                                                                                                                           |prediction|\n",
      "+------------+-----+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|0008221E6CF5|39226|1.0  |[0.035635907556186466,0.14254561284049766,0.03808905562764309,0.043948507950378704,0.07281365371469758,0.03618251850362804,0.08919417659482518,0.07142581397406755,0.1370727669424442,0.07789012581975714,0.06058592596217798,0.030021154197109545,0.04752531194894332,0.04249306344854594,0.062255240517981085,0.012321164401116497] |1.0       |\n",
      "|000EC6DC7BE2|49814|2.0  |[0.09997764776177562,0.16078721903858303,0.055393149620697274,0.041103787923319264,0.09978555118890356,0.0735327583603111,0.05602810384852374,0.11027059709744938,0.08105028601182351,0.03605523298154187,0.08322088063036619,0.00618072435311151,0.024905645479242358,0.05036834502508758,0.016745766419545123,0.004594304259718959] |1.0       |\n",
      "|001636154AF9|49813|5.0  |[0.049436040688350336,0.13659381086463424,0.09976315735031875,0.05215570225997497,0.09759006226125676,0.0712335127029704,0.11130988386706238,0.07683871975201507,0.07993060442859867,0.019321178464073822,0.03460227627364527,0.031576370401065944,0.01644874234306388,0.09731434232947558,0.02226028294652411,0.0036253130669696553] |1.0       |\n",
      "|0016785B0DF5|49810|3.0  |[0.07558133177048072,0.11282642998604468,0.06590880048915454,0.05779104426598654,0.11021088012254388,0.0755199873137308,0.07000923283494531,0.06691313370140936,0.08331974708870912,0.012403863935850084,0.06740741321190391,0.10199468743183558,0.024849003430833076,0.01849021675133191,0.05102933874196741,0.005744888923273319]   |1.0       |\n",
      "|0019CBF145D0|49807|0.0  |[0.11041372331225864,0.17270964245611323,0.048045663429484846,0.09207113933835655,0.05489444528747961,0.07043484797224178,0.06729960661338608,0.09871549911489087,0.10791775016790676,0.011060827378115173,0.06601222184565858,0.005240079901512119,0.04110518668988049,0.0389485537185485,0.010139927422855114,0.0049908853513115845]|1.0       |\n",
      "+------------+-----+-----+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('mac','id','label','probability','prediction').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mac', 'string'),\n",
       " ('id', 'string'),\n",
       " ('f1', 'float'),\n",
       " ('f2', 'float'),\n",
       " ('f3', 'float'),\n",
       " ('f4', 'float'),\n",
       " ('f5', 'float'),\n",
       " ('f6', 'float'),\n",
       " ('f7', 'float'),\n",
       " ('f8', 'float'),\n",
       " ('f9', 'float'),\n",
       " ('f10', 'float'),\n",
       " ('f11', 'float'),\n",
       " ('f12', 'float'),\n",
       " ('features', 'vector'),\n",
       " ('label', 'double'),\n",
       " ('rawPrediction', 'vector'),\n",
       " ('probability', 'vector'),\n",
       " ('prediction', 'double')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----------+\n",
      "|id   |label|prediction|\n",
      "+-----+-----+----------+\n",
      "|39226|1.0  |1.0       |\n",
      "|49814|2.0  |1.0       |\n",
      "|49813|5.0  |1.0       |\n",
      "|49810|3.0  |1.0       |\n",
      "|49807|0.0  |1.0       |\n",
      "|49808|6.0  |10.0      |\n",
      "|10679|15.0 |1.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "|10680|10.0 |10.0      |\n",
      "|10680|10.0 |10.0      |\n",
      "|10680|10.0 |10.0      |\n",
      "|10680|10.0 |10.0      |\n",
      "|39147|7.0  |0.0       |\n",
      "|39226|1.0  |0.0       |\n",
      "|39000|8.0  |0.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "+-----+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('id','label','prediction').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table = result.select('id','label').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping_table.write.mode('overwrite').parquet('hdfs:///data/user/hive/warehouse/ian/feature/mapping_table',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table = mapping_table.withColumnRenamed('id','predict_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.select('mac','prediction')\n",
    "final_result = result.join(mapping_table,result.prediction == mapping_table.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = final_result.select('mac','predict_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|mac         |predict_id|\n",
      "+------------+----------+\n",
      "|8C8590DA1CCB|49813     |\n",
      "|DCA4CA216A52|49814     |\n",
      "|00B362D13FDD|49809     |\n",
      "|38CADA970EF3|49809     |\n",
      "|B844D9DBFB9F|49808     |\n",
      "|5433CB5B8F9E|39226     |\n",
      "|649ABE637666|49807     |\n",
      "|7014A6CA6D7C|49807     |\n",
      "|D88F76C7CFEF|39226     |\n",
      "|24F6773B8DBB|49814     |\n",
      "|844167A3A34C|49807     |\n",
      "|40261961E073|39147     |\n",
      "|6C4D73481425|39147     |\n",
      "|483B3895CD20|49809     |\n",
      "|50A67FA7A883|49880     |\n",
      "|68EF43BF12BA|39147     |\n",
      "|48A195707F1E|49814     |\n",
      "|DC2B2A2A969A|49809     |\n",
      "|40831DA2E1CE|49813     |\n",
      "|C0CCF84C4B98|49810     |\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_result.sample(0.0001).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+---+----+---+---+---+---+----+----+---+----+----+----+--------------------+-----+\n",
      "|         mac|   id| f1|  f2| f3| f4| f5| f6|  f7|  f8| f9| f10| f11| f12|            features|label|\n",
      "+------------+-----+---+----+---+---+---+---+----+----+---+----+----+----+--------------------+-----+\n",
      "|8C8590DA1CCB|49814|8.0|12.0|8.0|5.0|9.0|0.0|13.0|10.0|1.0|12.0|12.0|11.0|[8.0,12.0,8.0,5.0...|  2.0|\n",
      "+------------+-----+---+----+---+---+---+---+----+----+---+----+----+----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.filter(testDF.mac == '8C8590DA1CCB').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crontab mac_id prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|mac         |predict_id|\n",
      "+------------+----------+\n",
      "|9CE33F6AF89B|39226     |\n",
      "|84A134385E87|49810     |\n",
      "|5433CB525C01|39226     |\n",
      "|70F087774375|49814     |\n",
      "|68DBCA53E6A9|49810     |\n",
      "|84A134093602|49810     |\n",
      "|C83C85E5A5F1|39226     |\n",
      "|404D7FE74BEE|49813     |\n",
      "|E0ACCB434FF3|49880     |\n",
      "|7C04D056B17E|49814     |\n",
      "|24F67750A0A7|49814     |\n",
      "|38C98692F03A|49880     |\n",
      "|94F6D6723318|39147     |\n",
      "|90B0EDB39F67|49810     |\n",
      "|68AB1E19EAB0|49880     |\n",
      "|9CE33F951EEA|39226     |\n",
      "|7C50495799BF|49814     |\n",
      "|DCA4CAD4D097|49814     |\n",
      "|70EF00427A61|39147     |\n",
      "|DC0C5C8D8A23|49814     |\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "model = RandomForestClassificationModel.load('/data/user/hive/warehouse/ian/model/mac_id_12_rf_cv_tuning_model')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF_mac_12') #change PATH\n",
    "result = model.transform(testDF)\n",
    "mapping_table = spark.read.parquet('/data/user/hive/warehouse/ian/feature/mapping_table').withColumnRenamed('id','predict_id')\n",
    "result = result.select('mac','prediction')\n",
    "final_result = result.join(mapping_table,result.prediction == mapping_table.label)\n",
    "final_result = final_result.select('mac','predict_id').distinct()\n",
    "final_result.sample(0.001).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|predict_id|count |\n",
      "+----------+------+\n",
      "|49810     |332712|\n",
      "|39890     |65343 |\n",
      "|49809     |320635|\n",
      "|49866     |60898 |\n",
      "|49880     |84506 |\n",
      "|39147     |225601|\n",
      "|49807     |415662|\n",
      "|39000     |24245 |\n",
      "|49814     |402567|\n",
      "|49813     |209372|\n",
      "|39226     |425120|\n",
      "|10679     |25368 |\n",
      "|10950     |139825|\n",
      "|10680     |126929|\n",
      "|49806     |74259 |\n",
      "|49808     |219770|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_result.groupBy('predict_id').count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnevsRest(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  pyspark.sql.functions import *\n",
    "trainDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/trainDF')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF')\n",
    "from pyspark.ml.classification import OneVsRest,LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "import numpy as np\n",
    "\n",
    "svc = LinearSVC()\n",
    "\n",
    "ovr = OneVsRest(classifier=svc)\n",
    "\n",
    "model = ovr.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('hdfs:///data/user/hive/warehouse/ian/model/mac_id_ovr_svc_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.classification import OneVsRestModel\n",
    "model = OneVsRestModel.load('hdfs:///data/user/hive/warehouse/ian/model/mac_id_ovr_svc_model')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF')\n",
    "result = model.transform(testDF.sample(0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result.withColumn('compare',when(result.label == result.prediction,1).otherwise(0)).select('mac','cn_name','label','prediction','compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|compare|count|\n",
      "+-------+-----+\n",
      "|      1|  343|\n",
      "|      0| 2836|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('compare').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnevsRest(NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  pyspark.sql.functions import *\n",
    "trainDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/trainDF')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF')\n",
    "\n",
    "from pyspark.ml.classification import OneVsRest,NaiveBayes\n",
    "\n",
    "nb = NaiveBayes()\n",
    "\n",
    "ovr = OneVsRest(classifier=nb)\n",
    "\n",
    "model = ovr.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('hdfs:///data/user/hive/warehouse/ian/model/mac_id_nb_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|compare|count|\n",
      "+-------+-----+\n",
      "|      1|  402|\n",
      "|      0| 2812|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import OneVsRestModel\n",
    "from pyspark.sql.functions import *\n",
    "model = OneVsRestModel.load('/data/user/hive/warehouse/ian/model/mac_id_nb_model')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF')\n",
    "result = model.transform(testDF.sample(0.001))\n",
    "df = result.withColumn('compare',when(result.label == result.prediction,1).otherwise(0)).select('mac','cn_name','label','prediction','compare')\n",
    "df.groupBy('compare').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
