{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    from pyspark.sql.functions import substring,conv,col,min,max,udf,lit\n",
    "   \n",
    "    d = spark.read.parquet('/data/user/hive/warehouse/ian/tmp_80AD16')\n",
    "    \n",
    "    bottom = d.select(min('p')).collect()[0]['min(p)']\n",
    "    top = d.select(max('p')).collect()[0]['max(p)'] \n",
    "    \n",
    "    if x < bottom:\n",
    "        return d.filter(d.p == bottom).select('id').collect()[0]['p']\n",
    "    \n",
    "    elif x > top:\n",
    "        return d.filter(d.p == top).select('id').collect()[0]['p']\n",
    "    \n",
    "    else :\n",
    "        p1 = test.filter(test.p == x)\n",
    "        p1 = p1.replace(p1.collect()[0]['id'],None)\n",
    "\n",
    "        from pyspark.sql import Window\n",
    "        from pyspark.sql.functions import row_number\n",
    "        window = Window.orderBy('p')\n",
    "\n",
    "        p1 = p1.unionByName(d1).sort('p',ascending=False)\n",
    "\n",
    "        d2 = p1.withColumn('index', row_number().over(window))\n",
    "\n",
    "        index = d2.filter(d2.p == 7431407).collect()[0]['index']\n",
    "\n",
    "        df = d2.where(col('index').between(index-5,index+5)).drop_duplicates().dropna()\n",
    "\n",
    "        tmp = df.groupBy('id').count()\n",
    "\n",
    "        return tmp.sort('count',ascending=False).collect()[0]['id'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import substring,conv,col\n",
    "\n",
    "test = spark.read.parquet('/data/user/hive/warehouse/ian/d6')\n",
    "\n",
    "result = []\n",
    "a = test.select('p').toPandas()['p'].values.tolist()\n",
    "for x in a:\n",
    "    result.append(predict(x))\n",
    "\n",
    "mac = test.select('mac').toPandas()['mac'].values.tolist()\n",
    "pre = spark.createDataFrame(pd.DataFrame({'mac':mac,'predict_id':result}))\n",
    "\n",
    "pre = pre.withColumnRenamed('mac','mac1')\n",
    "dd = test.join(pre,test.mac == pre.mac1,how='left')\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "dd = dd.withColumn('equal',when(dd.predict_id == dd.id, 1).otherwise(0))\n",
    "\n",
    "dd.groupBy('equal').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
