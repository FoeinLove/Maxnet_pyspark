{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+---+---+---+----+----+----+----+----+---+----+----+---+-------------------------------------------------------+-----+\n",
      "|mac         |id   |f1 |f2 |f3 |f4  |f5  |f6  |f7  |f8  |f9 |f10 |f11 |f12|features                                               |label|\n",
      "+------------+-----+---+---+---+----+----+----+----+----+---+----+----+---+-------------------------------------------------------+-----+\n",
      "|0008221E6CF5|39226|0.0|0.0|0.0|8.0 |2.0 |2.0 |1.0 |14.0|6.0|12.0|15.0|5.0|[0.0,0.0,0.0,8.0,2.0,2.0,1.0,14.0,6.0,12.0,15.0,5.0]   |1.0  |\n",
      "|000EC6DC7BE2|49814|0.0|0.0|0.0|14.0|12.0|6.0 |13.0|12.0|7.0|11.0|14.0|2.0|[0.0,0.0,0.0,14.0,12.0,6.0,13.0,12.0,7.0,11.0,14.0,2.0]|2.0  |\n",
      "|001636154AF9|49813|0.0|0.0|1.0|6.0 |3.0 |6.0 |1.0 |5.0 |4.0|10.0|15.0|9.0|[0.0,0.0,1.0,6.0,3.0,6.0,1.0,5.0,4.0,10.0,15.0,9.0]    |5.0  |\n",
      "|0016785B0DF5|49810|0.0|0.0|1.0|6.0 |7.0 |8.0 |5.0 |11.0|0.0|13.0|15.0|5.0|[0.0,0.0,1.0,6.0,7.0,8.0,5.0,11.0,0.0,13.0,15.0,5.0]   |3.0  |\n",
      "|0019CBF145D0|49807|0.0|0.0|1.0|9.0 |12.0|11.0|15.0|1.0 |4.0|5.0 |13.0|0.0|[0.0,0.0,1.0,9.0,12.0,11.0,15.0,1.0,4.0,5.0,13.0,0.0]  |0.0  |\n",
      "+------------+-----+---+---+---+----+----+----+----+----+---+----+----+---+-------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "trainDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF')\n",
    "\n",
    "trainDF = trainDF.withColumn('m1',substring(trainDF.mac,1,1)).\\\n",
    "      withColumn('m2',substring(trainDF.mac,2,1)).\\\n",
    "      withColumn('m3',substring(trainDF.mac,3,1)).\\\n",
    "      withColumn('m4',substring(trainDF.mac,4,1)).\\\n",
    "      withColumn('m5',substring(trainDF.mac,5,1)).\\\n",
    "      withColumn('m6',substring(trainDF.mac,6,1)).\\\n",
    "      withColumn('m7',substring(trainDF.mac,7,1)).\\\n",
    "      withColumn('m8',substring(trainDF.mac,8,1)).\\\n",
    "      withColumn('m9',substring(trainDF.mac,9,1)).\\\n",
    "      withColumn('m10',substring(trainDF.mac,10,1)).\\\n",
    "      withColumn('m11',substring(trainDF.mac,11,1)).\\\n",
    "      withColumn('m12',substring(trainDF.mac,12,1))\n",
    "\n",
    "df = trainDF.withColumn('f1',conv(trainDF.m1, 16, 10)).withColumn('f2',conv(trainDF.m2, 16, 10)).\\\n",
    "        withColumn('f3',conv(trainDF.m3, 16, 10)).withColumn('f4',conv(trainDF.m4, 16, 10)).\\\n",
    "        withColumn('f5',conv(trainDF.m5, 16, 10)).withColumn('f6',conv(trainDF.m6, 16, 10)).\\\n",
    "        withColumn('f7',conv(trainDF.m7, 16, 10)).withColumn('f8',conv(trainDF.m8, 16, 10)).\\\n",
    "        withColumn('f9',conv(trainDF.m9, 16, 10)).withColumn('f10',conv(trainDF.m10, 16, 10)).\\\n",
    "        withColumn('f11',conv(trainDF.m11, 16, 10)).withColumn('f12',conv(trainDF.m12, 16, 10))\n",
    "\n",
    "df = df.select('mac','id',col('f1').cast('float'),col('f2').cast('float')\\\n",
    "               ,col('f3').cast('float'),col('f4').cast('float')\\\n",
    "               ,col('f5').cast('float'),col('f6').cast('float')\\\n",
    "               ,col('f7').cast('float'),col('f8').cast('float')\\\n",
    "               ,col('f9').cast('float'),col('f10').cast('float')\\\n",
    "               ,col('f11').cast('float'),col('f12').cast('float'))\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vec = VectorAssembler(inputCols=['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12'],outputCol='features')\n",
    "new_df = vec.transform(df)\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "si = StringIndexer(inputCol='id', outputCol='label')\n",
    "si_model = si.fit(new_df)\n",
    "df_final = si_model.transform(new_df)\n",
    "\n",
    "df_final.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.write.mode('overwrite').parquet('hdfs:///data/user/hive/warehouse/ian/feature/testDF_mac_12',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with non cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/trainDF_apple')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF_apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7288049, 3121586)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count(),testDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol='label',featuresCol='features',numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mac', 'string'),\n",
       " ('id', 'string'),\n",
       " ('cn_name', 'string'),\n",
       " ('f1', 'float'),\n",
       " ('f2', 'float'),\n",
       " ('f3', 'float'),\n",
       " ('f4', 'float'),\n",
       " ('f5', 'float'),\n",
       " ('f6', 'float'),\n",
       " ('f7', 'float'),\n",
       " ('f8', 'float'),\n",
       " ('f9', 'float'),\n",
       " ('f10', 'float'),\n",
       " ('f11', 'float'),\n",
       " ('f12', 'float'),\n",
       " ('features', 'vector'),\n",
       " ('label', 'double'),\n",
       " ('rawPrediction', 'vector'),\n",
       " ('probability', 'vector'),\n",
       " ('prediction', 'double')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------------+\n",
      "|label|prediction|mac         |\n",
      "+-----+----------+------------+\n",
      "|5.0  |5.0       |000726429552|\n",
      "|1.0  |1.0       |0007E93000C0|\n",
      "|8.0  |5.0       |00082284245B|\n",
      "|1.0  |5.0       |000B2F545632|\n",
      "|1.0  |1.0       |000CE74FC714|\n",
      "+-----+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('label','prediction','mac').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4759468424063921"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with CV & hp tuning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/trainDF_apple')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF_apple')\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "import numpy as np\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "paramGrid_rf = ParamGridBuilder()\\\n",
    "       .addGrid(rf.maxDepth,[3,4,5,6,7,8,9,10])\\\n",
    "       .addGrid(rf.numTrees,[10,15,20,25,30])\\\n",
    "       .build()\n",
    "\n",
    "crossval_rf = CrossValidator(estimator=rf,\n",
    "                            estimatorParamMaps=paramGrid_rf,\n",
    "                            evaluator=MulticlassClassificationEvaluator(),\n",
    "                            numFolds=5)\n",
    "\n",
    "cvModel_rf = crossval_rf.fit(trainDF)\n",
    "\n",
    "best_model_rf = cvModel_rf.bestModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_eval_rf = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_eval_rf.evaluate(best_model_rf.transform(testDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model_rf.save('hdfs:///data/user/hive/warehouse/ian/model/mac_id_12_rf_cv_tuning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = best_model_rf.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----------+\n",
      "|id   |label|prediction|\n",
      "+-----+-----+----------+\n",
      "|39226|1.0  |1.0       |\n",
      "|49814|2.0  |1.0       |\n",
      "|49813|5.0  |1.0       |\n",
      "|49810|3.0  |1.0       |\n",
      "|49807|0.0  |1.0       |\n",
      "|49808|6.0  |10.0      |\n",
      "|10679|15.0 |1.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "|10680|10.0 |10.0      |\n",
      "|10680|10.0 |10.0      |\n",
      "|10680|10.0 |10.0      |\n",
      "|10680|10.0 |10.0      |\n",
      "|39147|7.0  |0.0       |\n",
      "|39226|1.0  |0.0       |\n",
      "|39000|8.0  |0.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "|49807|0.0  |0.0       |\n",
      "+-----+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select('id','label','prediction').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table = result.select('id','label').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping_table.write.mode('overwrite').parquet('hdfs:///data/user/hive/warehouse/ian/feature/mapping_table',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table = mapping_table.withColumnRenamed('id','predict_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.select('mac','prediction')\n",
    "final_result = result.join(mapping_table,result.prediction == mapping_table.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = final_result.select('mac','predict_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|mac         |predict_id|\n",
      "+------------+----------+\n",
      "|8C8590DA1CCB|49813     |\n",
      "|DCA4CA216A52|49814     |\n",
      "|00B362D13FDD|49809     |\n",
      "|38CADA970EF3|49809     |\n",
      "|B844D9DBFB9F|49808     |\n",
      "|5433CB5B8F9E|39226     |\n",
      "|649ABE637666|49807     |\n",
      "|7014A6CA6D7C|49807     |\n",
      "|D88F76C7CFEF|39226     |\n",
      "|24F6773B8DBB|49814     |\n",
      "|844167A3A34C|49807     |\n",
      "|40261961E073|39147     |\n",
      "|6C4D73481425|39147     |\n",
      "|483B3895CD20|49809     |\n",
      "|50A67FA7A883|49880     |\n",
      "|68EF43BF12BA|39147     |\n",
      "|48A195707F1E|49814     |\n",
      "|DC2B2A2A969A|49809     |\n",
      "|40831DA2E1CE|49813     |\n",
      "|C0CCF84C4B98|49810     |\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_result.sample(0.0001).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+---+----+---+---+---+---+----+----+---+----+----+----+--------------------+-----+\n",
      "|         mac|   id| f1|  f2| f3| f4| f5| f6|  f7|  f8| f9| f10| f11| f12|            features|label|\n",
      "+------------+-----+---+----+---+---+---+---+----+----+---+----+----+----+--------------------+-----+\n",
      "|8C8590DA1CCB|49814|8.0|12.0|8.0|5.0|9.0|0.0|13.0|10.0|1.0|12.0|12.0|11.0|[8.0,12.0,8.0,5.0...|  2.0|\n",
      "+------------+-----+---+----+---+---+---+---+----+----+---+----+----+----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.filter(testDF.mac == '8C8590DA1CCB').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crontab mac_id prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|mac         |predict_id|\n",
      "+------------+----------+\n",
      "|ECADB8719CA6|49866     |\n",
      "|B8C111A99F24|39226     |\n",
      "|649ABE71B5D0|49807     |\n",
      "|8489AD949EC9|49807     |\n",
      "|D461DA1A2825|39147     |\n",
      "|4C32757E1FA0|49866     |\n",
      "|00CDFE530E6F|49809     |\n",
      "|ECADB806B025|49880     |\n",
      "|2078F0AD2E87|49880     |\n",
      "|F8279307EF41|49806     |\n",
      "|E49ADC79CA71|39226     |\n",
      "|F0DBE2AAAEDA|49807     |\n",
      "|D81D72C96C00|49808     |\n",
      "|703C6947FE47|10950     |\n",
      "|0CD7460C8518|49810     |\n",
      "|58E6BAA3071F|39890     |\n",
      "|5CF7E69B2E63|49809     |\n",
      "|E49A793DAD52|49809     |\n",
      "|C83C85CD9318|39226     |\n",
      "|BCA920CE4956|49814     |\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "model = RandomForestClassificationModel.load('/data/user/hive/warehouse/ian/model/mac_id_12_rf_cv_tuning_model')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF_mac_12') #change PATH\n",
    "result = model.transform(testDF)\n",
    "mapping_table = spark.read.parquet('/data/user/hive/warehouse/ian/feature/mapping_table').withColumnRenamed('id','predict_id')\n",
    "result = result.select('mac','prediction')\n",
    "final_result = result.join(mapping_table,result.prediction == mapping_table.label)\n",
    "final_result = final_result.select('mac','predict_id').distinct()\n",
    "final_result.sample(0.0001).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+---+---+---+----+----+----+---+---+----+---+----+---+--------------------+-----+\n",
      "|         mac|   id| f1| f2| f3|  f4|  f5|  f6| f7| f8|  f9|f10| f11|f12|            features|label|\n",
      "+------------+-----+---+---+---+----+----+----+---+---+----+---+----+---+--------------------+-----+\n",
      "|649ABE71B5D0|49807|6.0|4.0|9.0|10.0|11.0|14.0|7.0|1.0|11.0|5.0|13.0|0.0|[6.0,4.0,9.0,10.0...|  0.0|\n",
      "+------------+-----+---+---+---+----+----+----+---+---+----+---+----+---+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.filter(testDF.mac == '649ABE71B5D0').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apple_mac_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "from pyspark.sql.functions import *\n",
    "model = RandomForestClassificationModel.load('/data/user/hive/warehouse/ian/model/mac_id_12_rf_cv_tuning_model')\n",
    "\n",
    "d1 = spark.read.csv('/user/maxnet/database/sig.db/data_visual_macinfo_res',sep='\\x01').select('_c0','_c4','_c5').distinct().withColumnRenamed('_c0','mac').withColumnRenamed('_c4','manu').withColumnRenamed('_c5','prior')\n",
    "d2 = d1.filter(d1.prior < 4)\n",
    "d3 = d2.filter(d2.manu == '苹果').select('mac')\n",
    "\n",
    "df = d3.withColumn('m1',substring(d3.mac,1,1))\\\n",
    "       .withColumn('m2',substring(d3.mac,2,1))\\\n",
    "       .withColumn('m3',substring(d3.mac,3,1))\\\n",
    "       .withColumn('m4',substring(d3.mac,4,1))\\\n",
    "       .withColumn('m5',substring(d3.mac,5,1))\\\n",
    "       .withColumn('m6',substring(d3.mac,6,1))\\\n",
    "       .withColumn('m7',substring(d3.mac,7,1))\\\n",
    "       .withColumn('m8',substring(d3.mac,8,1))\\\n",
    "       .withColumn('m9',substring(d3.mac,9,1))\\\n",
    "       .withColumn('m10',substring(d3.mac,10,1))\\\n",
    "       .withColumn('m11',substring(d3.mac,11,1))\\\n",
    "       .withColumn('m12',substring(d3.mac,12,1))  \n",
    "\n",
    "df = df.withColumn('f1',conv(df.m1, 16, 10)).withColumn('f2',conv(df.m2, 16, 10))\\\n",
    "                         .withColumn('f3',conv(df.m3, 16, 10)).withColumn('f4',conv(df.m4, 16, 10))\\\n",
    "                         .withColumn('f5',conv(df.m5, 16, 10)).withColumn('f6',conv(df.m6, 16, 10))\\\n",
    "                         .withColumn('f7',conv(df.m7, 16, 10)).withColumn('f8',conv(df.m8, 16, 10))\\\n",
    "                         .withColumn('f9',conv(df.m9, 16, 10)).withColumn('f10',conv(df.m10, 16, 10))\\\n",
    "                         .withColumn('f11',conv(df.m11, 16, 10)).withColumn('f12',conv(df.m12, 16, 10))\n",
    "\n",
    "df = df.select('mac',\\\n",
    "                col('f1').cast('float'),col('f2').cast('float'),\\\n",
    "                col('f3').cast('float'),col('f4').cast('float'),\\\n",
    "                col('f5').cast('float'),col('f6').cast('float'),\\\n",
    "                col('f7').cast('float'),col('f8').cast('float'),\\\n",
    "                col('f9').cast('float'),col('f10').cast('float'),\\\n",
    "                col('f11').cast('float'),col('f12').cast('float'))\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vec = VectorAssembler(inputCols=['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12'],outputCol='features')\n",
    "df = vec.transform(df)\n",
    "\n",
    "result = model.transform(df)\n",
    "mapping_table = spark.read.parquet('/data/user/hive/warehouse/ian/feature/mapping_table').withColumnRenamed('id','predict_id')\n",
    "result = result.select('mac','prediction')\n",
    "tmp = result.join(mapping_table,result.prediction == mapping_table.label)\n",
    "prediction = tmp.select('mac','predict_id').distinct()\n",
    "\n",
    "prediction.write.saveAsTable(\"sig.apple_mac_prediction\", None, \"overwrite\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
