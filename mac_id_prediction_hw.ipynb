{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with non cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/trainDF_hw')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF_hw')\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "rf = RandomForestClassifier(labelCol='label',featuresCol='features',numTrees=30)\n",
    "model = rf.fit(trainDF)\n",
    "predictions = model.transform(testDF)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy')\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with CV & hp tuning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/trainDF_hw')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF_hw')\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "import numpy as np\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "paramGrid_rf = ParamGridBuilder()\\\n",
    "       .addGrid(rf.maxDepth,[3,4,5,6,7,8,9,10])\\\n",
    "       .addGrid(rf.numTrees,[10,15,20,25,30])\\\n",
    "       .build()\n",
    "\n",
    "crossval_rf = CrossValidator(estimator=rf,\n",
    "                            estimatorParamMaps=paramGrid_rf,\n",
    "                            evaluator=MulticlassClassificationEvaluator(),\n",
    "                            numFolds=5)\n",
    "\n",
    "cvModel_rf = crossval_rf.fit(trainDF)\n",
    "\n",
    "best_model_rf = cvModel_rf.bestModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "my_eval_rf = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "my_eval_rf.evaluate(best_model_rf.transform(testDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model_rf.save('hdfs:///data/user/hive/warehouse/ian/model/mac_id_12_rf_cv_tuning_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = best_model_rf.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table = result.select('id','label').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping_table.write.mode('overwrite').parquet('hdfs:///data/user/hive/warehouse/ian/feature/mapping_table',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table = mapping_table.withColumnRenamed('id','predict_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.select('mac','prediction')\n",
    "final_result = result.join(mapping_table,result.prediction == mapping_table.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = final_result.select('mac','predict_id').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|mac         |predict_id|\n",
      "+------------+----------+\n",
      "|8C8590DA1CCB|49813     |\n",
      "|DCA4CA216A52|49814     |\n",
      "|00B362D13FDD|49809     |\n",
      "|38CADA970EF3|49809     |\n",
      "|B844D9DBFB9F|49808     |\n",
      "|5433CB5B8F9E|39226     |\n",
      "|649ABE637666|49807     |\n",
      "|7014A6CA6D7C|49807     |\n",
      "|D88F76C7CFEF|39226     |\n",
      "|24F6773B8DBB|49814     |\n",
      "|844167A3A34C|49807     |\n",
      "|40261961E073|39147     |\n",
      "|6C4D73481425|39147     |\n",
      "|483B3895CD20|49809     |\n",
      "|50A67FA7A883|49880     |\n",
      "|68EF43BF12BA|39147     |\n",
      "|48A195707F1E|49814     |\n",
      "|DC2B2A2A969A|49809     |\n",
      "|40831DA2E1CE|49813     |\n",
      "|C0CCF84C4B98|49810     |\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_result.sample(0.0001).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+---+----+---+---+---+---+----+----+---+----+----+----+--------------------+-----+\n",
      "|         mac|   id| f1|  f2| f3| f4| f5| f6|  f7|  f8| f9| f10| f11| f12|            features|label|\n",
      "+------------+-----+---+----+---+---+---+---+----+----+---+----+----+----+--------------------+-----+\n",
      "|8C8590DA1CCB|49814|8.0|12.0|8.0|5.0|9.0|0.0|13.0|10.0|1.0|12.0|12.0|11.0|[8.0,12.0,8.0,5.0...|  2.0|\n",
      "+------------+-----+---+----+---+---+---+---+----+----+---+----+----+----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.filter(testDF.mac == '8C8590DA1CCB').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crontab mac_id prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+\n",
      "|mac         |predict_id|\n",
      "+------------+----------+\n",
      "|9CE33F6AF89B|39226     |\n",
      "|84A134385E87|49810     |\n",
      "|5433CB525C01|39226     |\n",
      "|70F087774375|49814     |\n",
      "|68DBCA53E6A9|49810     |\n",
      "|84A134093602|49810     |\n",
      "|C83C85E5A5F1|39226     |\n",
      "|404D7FE74BEE|49813     |\n",
      "|E0ACCB434FF3|49880     |\n",
      "|7C04D056B17E|49814     |\n",
      "|24F67750A0A7|49814     |\n",
      "|38C98692F03A|49880     |\n",
      "|94F6D6723318|39147     |\n",
      "|90B0EDB39F67|49810     |\n",
      "|68AB1E19EAB0|49880     |\n",
      "|9CE33F951EEA|39226     |\n",
      "|7C50495799BF|49814     |\n",
      "|DCA4CAD4D097|49814     |\n",
      "|70EF00427A61|39147     |\n",
      "|DC0C5C8D8A23|49814     |\n",
      "+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "model = RandomForestClassificationModel.load('/data/user/hive/warehouse/ian/model/mac_id_12_rf_cv_tuning_model')\n",
    "testDF = spark.read.parquet('/data/user/hive/warehouse/ian/feature/testDF_mac_12') #change PATH\n",
    "result = model.transform(testDF)\n",
    "mapping_table = spark.read.parquet('/data/user/hive/warehouse/ian/feature/mapping_table').withColumnRenamed('id','predict_id')\n",
    "result = result.select('mac','prediction')\n",
    "final_result = result.join(mapping_table,result.prediction == mapping_table.label)\n",
    "final_result = final_result.select('mac','predict_id').distinct()\n",
    "final_result.sample(0.001).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|predict_id|count |\n",
      "+----------+------+\n",
      "|49810     |332712|\n",
      "|39890     |65343 |\n",
      "|49809     |320635|\n",
      "|49866     |60898 |\n",
      "|49880     |84506 |\n",
      "|39147     |225601|\n",
      "|49807     |415662|\n",
      "|39000     |24245 |\n",
      "|49814     |402567|\n",
      "|49813     |209372|\n",
      "|39226     |425120|\n",
      "|10679     |25368 |\n",
      "|10950     |139825|\n",
      "|10680     |126929|\n",
      "|49806     |74259 |\n",
      "|49808     |219770|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_result.groupBy('predict_id').count().show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
